{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "- Import numpy as np and pandas as pd"
   ],
   "metadata": {
    "id": "ld2wHkzA8K2e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.datasets import load_breast_cancer"
   ],
   "outputs": [],
   "metadata": {
    "executionInfo": {
     "elapsed": 1900,
     "status": "ok",
     "timestamp": 1603374451217,
     "user": {
      "displayName": "KRITHIKA RAVICHANDRAN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRtNeUUcu0-DB4HFBeZny6UwE_CwAAUzhgVXSorw=s64",
      "userId": "05010535168312002796"
     },
     "user_tz": -330
    },
    "id": "0zQIrieYs0N9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define method initialiseNetwork() initilise weights with zeros of shape(num_features, 1) and also bias b to zero\n",
    "- parameters: num_features(number of input features)\n",
    "- returns : dictionary of weight vector and bias"
   ],
   "metadata": {
    "id": "5wsb69rS8abF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def initialiseNetwork(num_features):\r\n",
    "  W = np.zeros((num_features, 1))\r\n",
    "  b = 0\r\n",
    "  parameters = {\"W\": W, \"b\": b}\r\n",
    "  return parameters"
   ],
   "outputs": [],
   "metadata": {
    "id": "i-wLAlQb2Drk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "define function sigmoid for the input z.  \n",
    "- parameters: z\n",
    "- returns: $1/(1+e^{(-z)})$"
   ],
   "metadata": {
    "id": "g2iUMm9XEW-s"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def sigmoid(z):\r\n",
    "  a =  1/(1 + np.exp(-z))\r\n",
    "  return a"
   ],
   "outputs": [],
   "metadata": {
    "id": "a_KB1o_e9S8F"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define method forwardPropagation() which implements forward propagtion defined as Z = (W.T dot_product X) + b, A = sigmoid(Z)\n",
    "- parameters: X, parameters\n",
    "- returns: A\n"
   ],
   "metadata": {
    "id": "G6TAbtJAFSva"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def forwardPropagation(X, parameters):\r\n",
    "  W = parameters[\"W\"]\r\n",
    "  b = parameters[\"b\"]\r\n",
    "  Z = np.dot(W.T,X) + b\r\n",
    "  A = sigmoid(Z)\r\n",
    "  return A"
   ],
   "outputs": [],
   "metadata": {
    "id": "l6FZS2nj92ev"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define function cost() which calculate the cost given by  −(sum(Y\\*log(A)+(1−Y)\\*log(1−A)))/num_samples, here * is elementwise product\n",
    "- parameters: A,Y,num_samples(number of samples)\n",
    "- returns: cost"
   ],
   "metadata": {
    "id": "IhMJx-ezHXWx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def cost(A, Y, num_samples):\n",
    "  cost = -1/num_samples *np.sum(Y*np.log(A) + (1-Y)*(np.log(1-A)))\n",
    "  return cost"
   ],
   "outputs": [],
   "metadata": {
    "id": "n52Rl7oCBj1L"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define method backPropgation() to get the derivatives of weigths and bias\n",
    "- parameters: X,Y,A,num_samples\n",
    "- returns: dW,db"
   ],
   "metadata": {
    "id": "jxXnhjd6ItFC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def backPropagration(X, Y, A, num_samples):\n",
    "  dZ =  A - Y                          \n",
    "  dW =  (np.dot(X,dZ.T))/num_samples                        #(X dot_product dZ.T)/num_samples\n",
    "  db =  np.sum(dZ)/num_samples                              #sum(dZ)/num_samples\n",
    "  return dW, db\n",
    "  "
   ],
   "outputs": [],
   "metadata": {
    "id": "U0ijyoESSGRT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define function updateParameters() to update current parameters with its derivatives  \n",
    "w = w - learning_rate \\* dw  \n",
    "b = b - learning_rate \\* db  \n",
    "parameters: parameters,dW,db, learning_rate   \n",
    "returns: dictionary of updated parameters"
   ],
   "metadata": {
    "id": "Yrclev_VKliY"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def updateParameters(parameters, dW, db, learning_rate):\n",
    "  W = parameters[\"W\"] - (learning_rate * dW)\n",
    "  b = parameters[\"b\"] - (learning_rate * db)\n",
    "  return {\"W\": W, \"b\": b}\n",
    "  "
   ],
   "outputs": [],
   "metadata": {
    "id": "9K1ubERjUdKj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the model for forward propagation  \n",
    "- parameters: X,Y, num_iter(number of iterations), learning_rate\n",
    "- returns: parameters(dictionary of updated weights and bias)"
   ],
   "metadata": {
    "id": "zKd5Nsvht5W7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def model(X, Y, num_iter, learning_rate):\n",
    "  num_features = X.shape[0]\n",
    "  num_samples = X.shape[1]\n",
    "  parameters = initialiseNetwork(num_features)                            #call initialiseNetwork()\n",
    "  for i in range(num_iter):\n",
    "    A = forwardPropagation(X, parameters)                              # calculate final output A from forwardPropagation()\n",
    "    if(i%100 == 0):\n",
    "      print(\"cost after {} iteration: {}\".format(i, cost(A, Y, num_samples)))\n",
    "    dW, db =  backPropagration(X, Y, A, num_samples)              # calculate  derivatives from backpropagation\n",
    "    parameters = updateParameters(parameters, dW, db, learning_rate)     # update parameters\n",
    "  return parameters\n",
    "    \n",
    "    \n",
    "  "
   ],
   "outputs": [],
   "metadata": {
    "id": "_QP4zvtoWkzw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Run the below cell to define the function to predict the output.It takes updated parameters and input data as function parameters and returns the predicted output"
   ],
   "metadata": {
    "id": "ISQKBz3DoY_h"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def predict(W, b, X):\n",
    "  Z = np.dot(W.T,X) + b\n",
    "  Y = np.array([1 if y > 0.5 else 0 for y in sigmoid(Z[0])]).reshape(1,len(Z[0]))\n",
    "  return Y"
   ],
   "outputs": [],
   "metadata": {
    "id": "RdK-4V8dZWmZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- The code in the below cell loads the breast cancer data set from sklearn.\n",
    "- The input variable(X_cancer) is about the dimensions of tumor cell and targrt variable(y_cancer) classifies tumor as malignant(0) or benign(1)"
   ],
   "metadata": {
    "id": "RN1AAlHbo7XF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "(X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "ai5s9pFFgG5g"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Split the data into train and test set using train_test_split(). Set the random state to 25. Refer the code snippet in topic 4"
   ],
   "metadata": {
    "id": "jUzT0JXXszzy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer,\n",
    "                                                   random_state = 25)"
   ],
   "outputs": [],
   "metadata": {
    "id": "nw_FdO__3dsF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the dimensions of tumor is not uniform you need to normalize the data before feeding to the network\n",
    "- The below function is used to normalize the input data."
   ],
   "metadata": {
    "id": "t-ZRhhx0sGR7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def normalize(data):\n",
    "  col_max = np.max(data, axis = 0)\n",
    "  col_min = np.min(data, axis = 0)\n",
    "  return np.divide(data - col_min, col_max - col_min)"
   ],
   "outputs": [],
   "metadata": {
    "id": "VR2PXnUDXtNd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Normalize X_train and X_test and assign it to X_train_n and X_test_n respectively"
   ],
   "metadata": {
    "id": "39IvMOIzt_fS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "X_train_n = normalize(X_train)\n",
    "X_test_n = normalize(X_test)"
   ],
   "outputs": [],
   "metadata": {
    "id": "ZgXdiH5QIAjV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Transpose X_train_n and X_test_n so that rows represents features and column represents the samples\n",
    "- Reshape Y_train and y_test into row vector whose length is equal to number of samples.Use np.reshape()\n",
    "\n"
   ],
   "metadata": {
    "id": "agS5nYAtuUng"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "X_trainT = X_train_n.T\n",
    "X_testT = X_test_n.T\n",
    "y_trainT = y_train.reshape(1,X_train_n.T.shape[1])\n",
    "y_testT =  y_test.reshape(1,X_testT.shape[1])"
   ],
   "outputs": [],
   "metadata": {
    "id": "yNFw2Gos9zZe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the network using X_trainT,y_trainT with number of iterations 4000 and learning rate 0.75"
   ],
   "metadata": {
    "id": "GP3WCFJbv-xE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "parameters = model(X_trainT, y_trainT, 4000, 0.75)                #call the model() function with parametrs mentioned in the above cell"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost after 0 iteration: 0.6931471805599453\n",
      "cost after 100 iteration: 0.24382767353051085\n",
      "cost after 200 iteration: 0.18414919195134818\n",
      "cost after 300 iteration: 0.1565873493485997\n",
      "cost after 400 iteration: 0.1396752246321806\n",
      "cost after 500 iteration: 0.1278729526958286\n",
      "cost after 600 iteration: 0.11900887751136768\n",
      "cost after 700 iteration: 0.1120266707270078\n",
      "cost after 800 iteration: 0.10633924623930974\n",
      "cost after 900 iteration: 0.10158933661241841\n",
      "cost after 1000 iteration: 0.09754476494426205\n",
      "cost after 1100 iteration: 0.0940469433647547\n",
      "cost after 1200 iteration: 0.09098323338346236\n",
      "cost after 1300 iteration: 0.08827107206470108\n",
      "cost after 1400 iteration: 0.08584834873491792\n",
      "cost after 1500 iteration: 0.0836673076013795\n",
      "cost after 1600 iteration: 0.08169053991796828\n",
      "cost after 1700 iteration: 0.07988826663984762\n",
      "cost after 1800 iteration: 0.0782364464730404\n",
      "cost after 1900 iteration: 0.07671542796224082\n",
      "cost after 2000 iteration: 0.07530896965280097\n",
      "cost after 2100 iteration: 0.07400351504064748\n",
      "cost after 2200 iteration: 0.07278764749502993\n",
      "cost after 2300 iteration: 0.07165167461890912\n",
      "cost after 2400 iteration: 0.07058730721875789\n",
      "cost after 2500 iteration: 0.06958740844345282\n",
      "cost after 2600 iteration: 0.06864579565976345\n",
      "cost after 2700 iteration: 0.06775708244509036\n",
      "cost after 2800 iteration: 0.06691655143817629\n",
      "cost after 2900 iteration: 0.06612005116932486\n",
      "cost after 3000 iteration: 0.06536391170175201\n",
      "cost after 3100 iteration: 0.06464487515951277\n",
      "cost after 3200 iteration: 0.06396003813267387\n",
      "cost after 3300 iteration: 0.06330680363111521\n",
      "cost after 3400 iteration: 0.06268284076971894\n",
      "cost after 3500 iteration: 0.06208605075546859\n",
      "cost after 3600 iteration: 0.061514538043587336\n",
      "cost after 3700 iteration: 0.06096658575859407\n",
      "cost after 3800 iteration: 0.06044063465393139\n",
      "cost after 3900 iteration: 0.05993526502299061\n"
     ]
    }
   ],
   "metadata": {
    "id": "6mGd_FK7GqHu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the output of test and train data using X_trainT and X_testT using predict() method> Use the parametes returned from the trained model\n"
   ],
   "metadata": {
    "id": "_YEgmlbxx11F"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "yPredTrain = predict(parameters[\"W\"], parameters[\"b\"], X_trainT)   # pass weigths and bias from parameters dictionary and X_trainT as input to the function\n",
    "yPredTest = predict(parameters[\"W\"], parameters[\"b\"], X_testT)    # pass the same parameters but X_testT as input data"
   ],
   "outputs": [],
   "metadata": {
    "id": "2GMgr9M8LqTn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Run the below cell print the accuracy of model on train and test data and save your answers. Donot modify the cell.**"
   ],
   "metadata": {
    "id": "Uv1oAgLW1a1E"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "a1=round(100 - np.mean(np.abs(yPredTrain - y_train)) * 100,2)\n",
    "a2=round(100 - np.mean(np.abs(yPredTest - y_test) * 100),2)\n",
    "print(\"train accuracy: {} %\".format(a1))\n",
    "print(\"test accuracy: {} %\".format(a2))\n",
    "\n",
    "import hashlib\n",
    "import pickle\n",
    "def gethex(ovalue):\n",
    "  hexresult=hashlib.md5(str(ovalue).encode())\n",
    "  return hexresult.hexdigest()\n",
    "\n",
    "\n",
    "def pickle_ans1(output):\n",
    "  hexresult=gethex(output)\n",
    "  with open('output/output1.pkl', 'wb') as file: \n",
    "    pickle.dump(hexresult,file)\n",
    "\n",
    "def pickle_ans2(output):\n",
    "  hexresult=gethex(output)\n",
    "  with open('output/output2.pkl', 'wb') as file: \n",
    "    pickle.dump(hexresult,file)\n",
    "\n",
    "\n",
    "pickle_ans1(a1)\n",
    "pickle_ans2(a2)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train accuracy: 98.59 %\n",
      "test accuracy: 93.01 %\n"
     ]
    }
   ],
   "metadata": {
    "cellView": "both",
    "executionInfo": {
     "elapsed": 1137,
     "status": "ok",
     "timestamp": 1603376740055,
     "user": {
      "displayName": "KRITHIKA RAVICHANDRAN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRtNeUUcu0-DB4HFBeZny6UwE_CwAAUzhgVXSorw=s64",
      "userId": "05010535168312002796"
     },
     "user_tz": -330
    },
    "id": "6RDW0GQbGWcU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": [],
   "name": "Basic_hands_on.ipynb",
   "provenance": [
    {
     "file_id": "1TvidTe-M5zDO1MDKJCBMnkMGgXbCxYA4",
     "timestamp": 1525431729338
    }
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "8f343f9d3947b1bc202c179c79a34308516e8b3cd03799b6703a1156c8f53686"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}